{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYW0Lo_E5kd3",
        "colab_type": "text"
      },
      "source": [
        "# Original ResNet\n",
        "- More layers purely leeds to gradient vanishing problems\n",
        "- It can be solved by normalizing initializations\n",
        "- As well as add intermediate normalization layers\n",
        "- Deeper network can also lead to unable to search for optimal as easy as shallow network. **Degradation**\n",
        "- Residual neural network solved degradation Problem.\n",
        "- The solver of SGD based on  BP might have difficulty solving many layers of non-linear functions.\n",
        "- A network might be redundantly deep, resnet make it possible to abandon some depth from time to time.\n",
        "\n",
        "## Methodology:\n",
        "- Using CIFRA-10 and ImageNet for benchmarking\n",
        "- ImageNet case: Use 152 layers.\n",
        "- This has better performance on other tasks like COCO detection and COCO segmentation.\n",
        "- It is generic; applicable to vision and non-vision problems.\n",
        "- 在训练，尝试的过程中：Batch Normalization 起到了关键的作用。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKQwoFdD33Oe",
        "colab_type": "code",
        "outputId": "9d2f8e7d-d700-40ba-d50a-6280c7258421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QJagH9nvwFm",
        "colab_type": "text"
      },
      "source": [
        "## Preparing TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAcnsa1HvvoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b0b09b23-67c2-41f7-f9b7-c459d378dd5c"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system 10.104.76.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system 10.104.76.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.104.76.250:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.104.76.250:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f0afd3882b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3UnNhICo7kZ",
        "colab_type": "text"
      },
      "source": [
        "## Build Flexiable architecture of ResNet\n",
        "- Data set should be CiFar-10\n",
        "- Define the residual block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrIIkMLXAJlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ResBlock(layers.Layer):\n",
        "  def __init__(self,name='resblock',channels=64,**kwargs):\n",
        "    super(ResBlock,self).__init__(name=name,**kwargs)\n",
        "    self.conv_1 = layers.Conv2D(channels,3,activation='relu'  ,padding='same')\n",
        "    self.batch_1= layers.BatchNormalization()\n",
        "    self.conv_2 = layers.Conv2D(channels,3,activation='relu',padding='same')\n",
        "    self.batch_2= layers.BatchNormalization()\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.conv_1(inputs[0])\n",
        "    x = self.batch_1(x)\n",
        "    x = self.conv_2(x)\n",
        "    x = self.batch_2(x)\n",
        "    index=0\n",
        "    if len(inputs) > 1:\n",
        "      index=1\n",
        "    x = layers.add([inputs[index],x])\n",
        "    x = tf.nn.relu(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKabkkMNDNPi",
        "colab_type": "text"
      },
      "source": [
        "## Construct the network based on ResBlock defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVgGTFYsDJNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  period_1 = [ResBlock(channels=64,name='resbock'+str(i)+'period_1') for i in range(3)]\n",
        "  period_2 = [ResBlock(channels=128,name='resbock'+str(i)+'period_2') for i in range(2)]\n",
        "  period_3 = [ResBlock(channels=256,name='resbock'+str(i)+'period_3') for i in range(5)]\n",
        "  period_4 = [ResBlock(channels=512,name='resbock'+str(i)+'period_4') for i in range(5)]\n",
        "\n",
        "  inputs = keras.Input(shape = (32,32,3),name='resnet')\n",
        "  x = layers.Conv2D(64,7,activation='relu',padding='same')(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPooling2D(2)(x)\n",
        "  for layer in period_1:\n",
        "    x = layer([x])\n",
        "\n",
        "  x = layers.MaxPooling2D(2)(x)\n",
        "  res_x = layers.Conv2D(128,1)(x) # Pure depth conv\n",
        "  x = ResBlock(channels=128,name='intermediate_1')(inputs=[x,res_x])\n",
        "  for layer in period_2:\n",
        "    x = layer([x])\n",
        "\n",
        "  x = layers.MaxPooling2D(2)(x)\n",
        "  res_x = layers.Conv2D(256,1)(x) # Pure depth conv\n",
        "  x = ResBlock(channels=256,name='intermediate_2')([x,res_x])\n",
        "  for layer in period_3:\n",
        "    x = layer([x])\n",
        "\n",
        "  #x = layers.MaxPooling2D(2)(x)\n",
        "  res_x = layers.Conv2D(512,1)(x) # Pure depth conv\n",
        "  x = ResBlock(channels=512,name='intermediate_3')([x,res_x])\n",
        "  for layer in period_4:\n",
        "    x = layer([x])\n",
        "\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  outputs = layers.Dense(10,activation='sigmoid')(x)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  keras.utils.plot_model(model,'model.jpg',show_shapes=True,expand_nested=True)\n",
        "  model.summary()\n",
        "  model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqeWlx1pKd_",
        "colab_type": "text"
      },
      "source": [
        "## Load CIFRA-10 Dataset\n",
        "- Preprocess and compress it into 32 * 32\n",
        "- Using tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9yM5h_kmYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=1000,\n",
        "          epochs=1000,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}